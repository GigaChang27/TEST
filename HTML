import streamlit as st
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler, MinMaxScaler
import numpy as np
import matplotlib.pyplot as plt
from sklearn.impute import SimpleImputer

# 讀取資料
@st.cache_data
def load_data(file_path):
    try:
        data = pd.read_csv(file_path)
        data.dropna(inplace=True)  # 處理缺失值
        return data
    except FileNotFoundError:
        st.error("找不到資料集")
        return None

# 主程式
def main():
    st.title('線性回歸分析應用')

    # 載入資料
    file_path = 'D:\AI project\data.csv'
    data = load_data(file_path)

    if data is None:
        return

    # 選擇特徵和目標變數
    features = st.multiselect('選擇特徵', data.columns.tolist())
    target = st.selectbox('選擇目標變數', data.columns.tolist())

    if not features:
        st.warning("請至少選擇一個特徵")
        return

    # 分割資料集
    X = data[features]
    y = data[target]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

    # 檢查資料是否違反規則
    violated_rules = False
    normality = st.checkbox('資料是否違反態性假設？')
    independence = st.checkbox('資料是否違反獨立性假設？')
    homoscedasticity = st.checkbox('資料是否違反同質性假設？')

    if normality or independence or homoscedasticity:
        violated_rules = True

    # 進行變數轉換
    if violated_rules:
        st.subheader('選擇變數轉換方式')
        scaler_option = st.radio('請選擇變數轉換方式', ['StandardScaler', 'MinMaxScaler', 'Log Transformation'])

        if scaler_option == 'StandardScaler':
            scaler = StandardScaler()
        elif scaler_option == 'MinMaxScaler':
            scaler = MinMaxScaler()
        elif scaler_option == 'Log Transformation':
            X_train = np.log1p(X_train)
            X_test = np.log1p(X_test)

        if scaler_option != 'Log Transformation':
            X_train = scaler.fit_transform(X_train)
            X_test = scaler.transform(X_test)

    # 建立並訓練線性回歸模型
    model = LinearRegression()
    model.fit(X_train, y_train)

    # 預測
    y_pred = model.predict(X_test)

    # 顯示結果
    st.subheader('回歸模型效果')
    st.write('R^2 score:', model.score(X_test, y_test))

    # 繪製預測結果
    fig, ax = plt.subplots()
    ax.scatter(y_test, y_pred)
    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)
    ax.set_xlabel('實際值')
    ax.set_ylabel('預測值')
    ax.set_title('線性回歸預測結果')
    st.pyplot(fig)

if __name__ == '__main__':
    main()
